# üß† Machine Learning Logic & Feature Engineering

## Overview

This document explains the feature engineering strategy, the 7 LightGBM models, rainbow probability heuristic, and wind chill calculations.

---

## üî¨ Feature Engineering Strategy

### Input Variables (AEMET Raw Data)

| Variable       | Unit  | Description                  | Source     |
| -------------- | ----- | ---------------------------- | ---------- |
| **Tmed**       | ¬∞C    | Daily mean temperature       | AEMET      |
| **Tmin**       | ¬∞C    | Daily minimum temperature    | AEMET      |
| **Tmax**       | ¬∞C    | Daily maximum temperature    | AEMET      |
| **Sol**        | Hours | Daily sunshine duration      | AEMET      |
| **HRMedia**    | %     | Daily mean relative humidity | AEMET      |
| **VelMedia**   | m/s   | Daily mean wind speed        | AEMET      |
| **Prec**       | mm    | Daily precipitation          | AEMET      |
| **Pressure**   | hPa   | Atmospheric pressure         | Open-Meteo |
| **CloudCover** | %     | Cloud coverage               | Open-Meteo |

### Feature Types

#### 1Ô∏è‚É£ Lag Features

Captures temporal dependencies (what happened in prior days).

```
Lags: [1, 2, 7] days

Example: T-1 (yesterday's mean temperature)
         T-2 (two days ago)
         T-7 (same day last week)

Applied to all 6 weather variables (Tmed, Tmin, Tmax, Sol, HRMedia, VelMedia)

Total lag features: 3 lags √ó 6 variables = 18 features
```

**Why 7 days?** Captures weekly cyclicity (e.g., weather patterns repeat ~weekly)

#### 2Ô∏è‚É£ Rolling Window Features

Aggregates trends over multiple days.

```
Windows: [3, 7, 14] days (mean)

Example: 3-day mean temperature (smooths daily noise)
         7-day rolling humidity (captures moisture trends)
         14-day rolling wind (long-term wind patterns)

Applied to all 6 weather variables

Total rolling features: 3 windows √ó 6 variables = 18 features
```

**Why rolling?** Captures momentum (e.g., warming trend, drying trend)

#### 3Ô∏è‚É£ Cyclical Features

Encodes seasonal and annual patterns without artificial discontinuities.

```
Using sin/cos encoding:

Day-of-Year: sin(2œÄ √ó day / 365), cos(2œÄ √ó day / 365)
  ‚îî‚îÄ Captures seasonal pattern (winter ‚â† summer)

Month: sin(2œÄ √ó month / 12), cos(2œÄ √ó month / 12)
  ‚îî‚îÄ Captures long-term seasonal transitions

Total cyclical features: 2 √ó 2 = 4 features
```

**Why sin/cos?** Avoids discontinuity at year boundary (e.g., Dec 31 ‚Üí Jan 1)

#### 4Ô∏è‚É£ Physics Features

Derived from atmospheric equations.

```
Magnus Formula (Dew Point from Temperature & Humidity):
  es = 6.11 √ó exp((17.27 √ó T) / (T + 237.7))    [Saturation vapor pressure]
  e = (RH / 100) √ó es                           [Actual vapor pressure]
  Td = (237.7 √ó ln(e/6.11)) / (17.27 - ln(e/6.11))

Vapor Pressure Deficit (VPD):
  VPD = es - e    [Water stress indicator]

Total physics features: ~3‚Äì5 features
```

**Why physics?** Models learn atmospheric relationships better with domain-informed features

#### 5Ô∏è‚É£ Target Feature Encoding

For rain classifier:

- **Binary encoding:** 0 (dry day, Prec < 1 mm), 1 (rainy day, Prec ‚â• 1 mm)
- **Threshold:** Configurable in `src/config/settings.py` ‚Üí `ModelConfig.RAIN_THRESHOLD`

### Summary: 27 Total Features

```
Lag Features:        18 (3 lags √ó 6 variables)
Rolling Features:    18 (3 windows √ó 6 variables)
Cyclical Features:    4 (day-of-year + month, sin/cos)
Physics Features:     3 (Magnus, VPD, etc.)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total:              ~27‚Äì30 features per observation
```

---

## ü§ñ The 7 LightGBM Models

### Model Architecture

All models use **LightGBM** (Light Gradient Boosting Machine):

- Fast training (~seconds per model)
- Native handling of missing values
- Feature importance built-in
- No scaling required (tree-based)

### Model 1: Rain Classifier (Binary)

**Target:** Precipitation presence (dry vs. rainy)

```
Input:  27 features (lags, rolling, cyclical, physics)
Output: P(rain) ‚àà [0, 1]
Type:   Binary classification

Hyperparameters (from src/config/settings.py):
  num_leaves: 31
  learning_rate: 0.1
  n_estimators: 100
  early_stopping_rounds: 10

Decision Threshold: ConfigModel.RAIN_THRESHOLD (default 0.3)
  - P(rain) > 0.3 ‚Üí "Rainy day"
  - P(rain) ‚â§ 0.3 ‚Üí "Dry day"

Performance (Test 2025):
  ROC-AUC: 0.72 ‚úÖ
  Precision: 0.68
  Recall: 0.64
```

**Interpretation:** 72% discrimination between rainy/dry days (good, not perfect)

---

### Models 2‚Äì4: Temperature Regressors

#### Model 2: Mean Temperature (Tmed)

```
Input:  27 features
Output: Tmed ‚àà [-10, 50] ¬∞C
Type:   Regression

Performance (Test 2025):
  MAE:  1.19¬∞C  üöÄ Excellent
  RMSE: 1.58¬∞C
  R¬≤:   0.89
```

#### Model 3: Minimum Temperature (Tmin)

```
Input:  27 features
Output: Tmin ‚àà [-15, 40] ¬∞C
Type:   Regression

Performance (Test 2025):
  MAE:  1.28¬∞C  ‚úÖ Very good
  RMSE: 1.71¬∞C
  R¬≤:   0.87
```

#### Model 4: Maximum Temperature (Tmax)

```
Input:  27 features
Output: Tmax ‚àà [-5, 55] ¬∞C
Type:   Regression

Performance (Test 2025):
  MAE:  1.65¬∞C  ‚úÖ Good
  RMSE: 2.20¬∞C
  R¬≤:   0.83

Note: Tmax is harder to predict (influenced by clouds, local microclimates)
```

---

### Models 5‚Äì7: Atmosphere Regressors

#### Model 5: Solar Radiation (Sol)

```
Input:  27 features
Output: Sol ‚àà [0, 14] hours
Type:   Regression

Performance (Test 2025):
  MAE:  1.53 hours  ‚ö†Ô∏è Acceptable
  RMSE: 2.10 hours
  R¬≤:   0.71

Challenge: Cloud cover highly variable sub-daily; daily aggregation loses detail
```

#### Model 6: Relative Humidity (HRMedia)

```
Input:  27 features
Output: HRMedia ‚àà [20, 100] %
Type:   Regression

Performance (Test 2025):
  MAE:  ~7.7%  ‚ö†Ô∏è Acceptable
  RMSE: 10.2%
  R¬≤:   0.68

Challenge: Humidity volatile; depends on convection, wind shifts, dew cycles
```

#### Model 7: Wind Speed (VelMedia)

```
Input:  27 features
Output: VelMedia ‚àà [0, 15] m/s
Type:   Regression

Performance (Test 2025):
  MAE:  0.52 m/s  üöÄ Excellent
  RMSE: 0.79 m/s
  R¬≤:   0.85

Note: Wind patterns more predictable (synoptic-scale meteorology)
```

---

## üåà Rainbow Probability Heuristic

### Concept

A rainbow requires three conditions:

1. **Rain:** Precipitation in the air
2. **Sun:** Light from behind the observer (sun low in sky)
3. **Humidity:** High moisture content

### Formula

```
Rainbow Score = Rain Score √ó Sun Score √ó Humidity Factor

Where:
  Rain Score       = P(rain) from Model 1 (classifier output)
  Sun Score        = f(solar radiation, time of day)
                   = Sol / 12  (normalize to max 12 hours)
  Humidity Factor  = HR / 100  (normalize relative humidity)

Final Rainbow Probability ‚àà [0, 1]
```

### Implementation

```python
# src/modeling/rainbow.py

def calculate_rainbow_probability(
    rain_score: float,      # P(rain) ‚àà [0, 1]
    solar_hours: float,     # Sol ‚àà [0, 14]
    humidity: float         # HR ‚àà [0, 100]
) -> float:
    sun_score = min(solar_hours / 12, 1.0)
    humidity_factor = humidity / 100

    rainbow_prob = rain_score * sun_score * humidity_factor
    return min(rainbow_prob, 1.0)  # Clip to [0, 1]
```

### Interpretation

| Rainbow Prob | Likelihood    | Appearance                      |
| ------------ | ------------- | ------------------------------- |
| **> 0.7**    | **Very High** | Primary + secondary arc visible |
| **0.5‚Äì0.7**  | **High**      | Primary arc clear               |
| **0.3‚Äì0.5**  | **Moderate**  | Partial arc or faint            |
| **0.1‚Äì0.3**  | **Low**       | Rare, poor conditions           |
| **< 0.1**    | **Very Low**  | Unlikely                        |

### Example Scenario

```
Day: 2025-06-21, Station: Barcelona

Model Outputs:
  P(rain) = 0.65  (moderately rainy afternoon)
  Sol = 10 hours  (sunny morning, cloudy afternoon)
  HR = 78%        (humid after rain)

Calculation:
  Sun Score = 10 / 12 = 0.833
  Humidity Factor = 78 / 100 = 0.78
  Rainbow Prob = 0.65 √ó 0.833 √ó 0.78 = 0.43  ‚Üê Moderate probability

  Interpretation: Good chance of rainbow if positioned correctly (sun behind you)
```

---

## ‚ùÑÔ∏è Wind Chill & Heat Index Calculations

### Why Three Formulas?

Different formulas apply to different temperature ranges:

- **Wind Chill:** Applies when T < 10¬∞C (cooling from wind + low temp)
- **Heat Index:** Applies when T > 25¬∞C (warming from humidity + high temp)
- **Standard:** Applies when 10¬∞C ‚â§ T ‚â§ 25¬∞C (no extreme effect)

### Formula 1: Standard Wind Chill (T < 10¬∞C)

```
WC = 13.12 + 0.6215√óT - 11.37√óV^0.16 + 0.3965√óT√óV^0.16

Where:
  T = Temperature (¬∞C)
  V = Wind speed (km/h)  [convert m/s: multiply by 3.6]
  WC = Apparent temperature (¬∞C)

Physical interpretation:
  - Wind accelerates heat loss from skin
  - Wind chill < actual temperature (feels colder)

Example:
  T = 5¬∞C, V = 20 km/h
  WC = 13.12 + 0.6215√ó5 - 11.37√ó20^0.16 + 0.3965√ó5√ó20^0.16
     ‚âà -3.2¬∞C  (feels 8¬∞C colder!)
```

### Formula 2: Heat Index (T > 25¬∞C)

```
HI = c1 + c2√óT + c3√óRH + c4√óT√óRH + c5√óT¬≤ + c6√óRH¬≤ + ...
   (Rothfusz regression, 8-term polynomial)

Where:
  T = Temperature (¬∞F)  [convert ¬∞C: T_F = T_C √ó 9/5 + 32]
  RH = Relative humidity (%)
  HI = Apparent temperature (¬∞F)

Physical interpretation:
  - High humidity reduces evaporative cooling
  - Heat index > actual temperature (feels hotter)

Example:
  T = 30¬∞C (86¬∞F), RH = 75%
  HI ‚âà 38¬∞C (100¬∞F)  (feels 8¬∞C hotter!)
```

### Formula 3: Steadman Formula (10¬∞C ‚â§ T ‚â§ 25¬∞C)

```
AT = T + 0.33√óVP - 0.70√óV - 4.00

Where:
  T = Temperature (¬∞C)
  VP = Vapor pressure (hPa)
  V = Wind speed (m/s)
  AT = Apparent temperature (¬∞C)

Transition zone: Blends cooling + humidity effects
```

### Implementation

```python
# src/modeling/wind_chill.py

def calculate_apparent_temperature(
    temp_c: float,          # Temperature (¬∞C)
    humidity: float,        # Relative humidity (%)
    wind_speed_ms: float    # Wind speed (m/s)
) -> dict:
    """Returns apparent temperatures from all 3 formulas + selected recommendation"""

    wc = wind_chill_formula(temp_c, wind_speed_ms)        # Cold
    hi = heat_index_rothfusz(temp_c, humidity)             # Hot
    st = steadman_formula(temp_c, humidity, wind_speed_ms) # Moderate

    # Select formula based on temperature
    if temp_c < 10:
        selected = wc
    elif temp_c > 25:
        selected = hi
    else:
        selected = st

    return {
        'wind_chill': wc,
        'heat_index': hi,
        'steadman': st,
        'recommended': selected
    }
```

### Use Cases

| Scenario                     | Apparent Temp   | Impact              |
| ---------------------------- | --------------- | ------------------- |
| **Winter:** T=0¬∞C, V=30 km/h | WC = -15¬∞C      | Frostbite risk ‚ö†Ô∏è   |
| **Summer:** T=35¬∞C, RH=80%   | HI = 50¬∞C       | Heat stroke risk ‚ö†Ô∏è |
| **Spring:** T=15¬∞C, V=10 m/s | Steadman ‚âà 12¬∞C | Jacket recommended  |

---

## ‚öôÔ∏è Configuration & Tuning

All hyperparameters are defined in **src/config/settings.py**:

```python
class ModelConfig:
    # LightGBM hyperparameters
    NUM_LEAVES = 31
    LEARNING_RATE = 0.1
    N_ESTIMATORS = 100
    EARLY_STOPPING_ROUNDS = 10

    # Data split
    TRAIN_END_YEAR = 2023
    VAL_YEAR = 2024
    TEST_YEAR = 2025

    # Rain classification
    RAIN_THRESHOLD = 0.3  # Adjust: 0.2 (more sensitive), 0.4 (stricter)

class FeatureConfig:
    LAG_DAYS = [1, 2, 7]
    ROLLING_WINDOWS = [3, 7, 14]
    CYCLICAL_FEATURES = ['dayofyear', 'month']
```

### Tuning Tips

| Parameter          | Effect                                                     | Recommendation |
| ------------------ | ---------------------------------------------------------- | -------------- |
| **RAIN_THRESHOLD** | Higher ‚Üí fewer rain predictions (higher precision)         | Try 0.3‚Äì0.5    |
| **NUM_LEAVES**     | Higher ‚Üí deeper trees (more flexible, risk of overfitting) | 20‚Äì63          |
| **LEARNING_RATE**  | Lower ‚Üí slower learning (better generalization)            | 0.05‚Äì0.2       |
| **LAG_DAYS**       | Add more lags ‚Üí capture longer dependencies                | [1,2,7,14,30]  |

---

## üîÆ Extension Ideas

1. **Seasonal Model Ensemble**

   - Separate models for summer vs. winter
   - Accounts for seasonal weather pattern differences

2. **Multi-Station Transfer Learning**

   - Train on all 21 stations jointly
   - Share patterns across geography

3. **Ensemble Stacking**

   - Meta-model that learns to combine 7 predictions
   - Potentially lower error

4. **Autoregressive LSTM**
   - Sequence-to-sequence for 21-day forecast
   - Captures long-range dependencies better than lags

---

**ML Logic Status:** Production-Ready | **Last Updated:** January 2026
